<!DOCTYPE html>
<!--
  Original Design: Spectral by HTML5 UP
    html5up.net | @n33co
    Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
  Jekyll build mod and further hacks by @arkadianriver, MIT license
-->
<html>
  <head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Text in Image 2.0 - improving OCR service with PaddleOCR</title>
  <meta name="google-site-verification" content="WrNs4kb-PL779UWOhOTLegwiql-42uVzYDfCoJxQRPs" />
  <meta name="description" content="Read how the Cognition team improved the Text in Image service across Adevinta marketplaces using PaddleOC">
  <!--[if lte IE 8]><script src="/js/ie/html5shiv.js"></script><![endif]-->
  <link rel="canonical" href="http://urszulaczerwinska.github.io/works/text-in-image-2-0-improving-ocr-service-with-paddleocr">
  <link rel="shortcut icon" href="/favicon.ico">

  <link rel="stylesheet" href="/css/main.css" />


  
  <!-- Add JSON-LD for Article and Person Schema -->
  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Article",
      "headline": "Text in Image 2.0 - improving OCR service with PaddleOCR"
      "description": "Learn how the Adevinta Cognition team improved the OCR service using PaddleOCR, enhancing the Text in Image service for global marketplaces with better accur...",
      "datePublished": "2023-03-06T00:00:00+01:00",
      "dateModified": "2023-03-06T00:00:00+01:00",
      "keywords": "data science, OCR, deep learning, computer vision, machine learning, API",
      "author": {
        "@type": "Person",
        "name": "Urszula Czerwinska",
        "description": "Data Scientist & Deep Learning Engineer",
        "url": "https://www.linkedin.com/in/urszula-czerwinska/"
      },
      "image": {
        "@type": "ImageObject",
        "url": "http://urszulaczerwinska.github.io/images/writing.jpeg",
        "width": 1200,
        "height": 630
      },
      "publisher": {
        "@type": "Organization",
        "name": "Urszula Czerwinska",
        "logo": {
          "@type": "ImageObject",
          "url": "http://urszulaczerwinska.github.io/images/logo.png",
          "width": 60,
          "height": 60
        }
      },
      "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://urszulaczerwinska.github.io/works/text-in-image-2-0-improving-ocr-service-with-paddleocr"
      }
    }
</script>


  <!--[if lte IE 8]><link rel="stylesheet" href="/css/ie8.css" /><![endif]-->
  <!--[if lte IE 9]><link rel="stylesheet" href="/css/ie9.css" /><![endif]-->
  <style>
  #main > header {
    background-image: -moz-linear-gradient(top, rgba(0,0,0,0.5), rgba(0,0,0,0.5)), url("/images/text-in-image-2.jpg");
    background-image: -webkit-linear-gradient(top, rgba(0,0,0,0.5), rgba(0,0,0,0.5)), url("/images/text-in-image-2.jpg");
    background-image: -ms-linear-gradient(top, rgba(0,0,0,0.5), rgba(0,0,0,0.5)), url("/images/text-in-image-2.jpg");
    background-image: linear-gradient(top, rgba(0,0,0,0.5), rgba(0,0,0,0.5)), url("/images/text-in-image-2.jpg");
  }
  </style>
  <!--[if lte IE 9]>
  <style>
  #main > header {
    background-image: url("/images/text-in-image-2.jpg");
  }
  </style>
  -->
  <link rel="alternate" type="application/rss+xml" title="Urszula Czerwinska | Data Scientist & Deep Learning Engineer" href="http://urszulaczerwinska.github.io/feed.xml">
</head>

  <!-- Semantic Schema generated by InLinks -->


  
  <body>


    <!-- Page Wrapper -->
    <div id="page-wrapper">

      <!-- Header -->
<header id="header">
  <h1><a href="/index.html"> <span><img src="/favicon.ico" alt="Logo" style="height: 40px; vertical-align: middle; margin-right: 5px;"> Urszula Czerwinska </span></a></h1>
  <nav id="nav">
    <ul>
      <li class="special">
        <a href="#menu" class="menuToggle">  <span>
          Menu
        </span></a>
        <div id="menu">
          <ul>
            <li><a href="/index.html">Home</a></li>
            <li><a href="/about/">About</a></li>
            <li><a href="/works/">Works</a></li>
            <li><a href="/thoughts/">Thoughts</a></li>
            <li><a href="/feed.xml"
                   class="icon fa-feed"> RSS Feed</a></li>
          </ul>
        </div>
      </li>
    </ul>
  </nav>
</header>


      <article id="main">

          <header>
    <h2>Text in Image 2.0 - improving OCR service with PaddleOCR</h2>
    <p>Read how the Cognition team improved the Text in Image service across Adevinta marketplaces using PaddleOC</p>
  </header>
  <ul class="breadcrumb">
  <li><a href="/index.html">Home</a></li>
  <li>Text in Image 2.0 - improving OCR service with PaddleOCR</li>
</ul>



          <section class="wrapper style5">
    <div class="inner">
      <span id="post-date">6 March 2023</span><hr
        style="margin-top:3px;" />
      <h4>Skills</h4>
  <ul class="techlist">
<li><span class="tech">data science</span></li>
<li><span class="tech">OCR</span></li>
<li><span class="tech">deep learning</span></li>
<li><span class="tech">computer vision</span></li>
<li><span class="tech">machine learning</span></li>
<li><span class="tech">API</span></li>
</ul>

  

      <head>
  <meta name="description" content="Discover how the Cognition team at Adevinta enhanced the Text in Image service using PaddleOCR, leading to significant improvements in OCR accuracy and performance." />
</head>

<h2 id="understanding-ocr-what-is-optical-character-recognition">Understanding OCR: What is Optical Character Recognition?</h2>

<p>Optical Character Recognition (OCR) is a popular topic for both industry and personal use. In this article, we share how we tested and used an existing open source library, PaddleOCR, to extract text from an image. This read is for anyone who would like to find out more about OCR, the needs of our customers at <a href="https://www.adevinta.com/">Adevinta</a>, and the challenges we face in attending to them. You’ll find out how we upgraded an existing service, benchmarked different solutions and delivered the selected one to satisfy our customers.</p>

<h2 id="key-ocr-applications-how-ocr-transforms-business-and-daily-operations">Key OCR applications: How OCR transforms business and daily operations</h2>

<p>OCR stands for “Optical Character Recognition” and is a technology that allows computers to recognise and extract text from images and scanned documents. OCR software uses optical recognition algorithms to interpret the text in images and convert it into machine-readable text that can be edited, searched and stored electronically.</p>

<p>There are numerous use-cases where OCR can be used:</p>

<ul>
  <li><strong>Digitising paper documents</strong>: to convert scanned images of text into digital text. This is useful for organisations that want to reduce their reliance on paper and improve their document management processes.</li>
  <li><strong>Extracting data from images</strong>: eg from documents such as invoices, receipts and forms. This can be useful for automating data entry tasks and reducing the need for manual data entry.</li>
  <li><strong>Translating documents</strong>: to extract text from images of documents written in foreign languages and translate them into a different language.</li>
  <li><strong>Archiving</strong>: to create digital copies of important documents that need to be preserved for long periods of time.</li>
  <li><strong>Improving accessibility</strong>: to make scanned documents more accessible to people with disabilities by converting the text into a format that can be read by assistive technologies such as screen readers.</li>
  <li><strong>Searching documents</strong>: to make scanned documents searchable, allowing users to easily find specific information within a large collection of documents.</li>
</ul>

<h2 id="the-adevinta-context-why-ocr-matters-in-global-marketplace">The Adevinta context: Why OCR matters in global marketplace</h2>

<p>Within <a href="https://www.adevinta.com/">Adevinta</a>, a global classifieds specialist with market-leading positions in key European markets, there is space for all of the cited use cases. However, for this article, we focus specifically on “extracting data from images.”</p>

<p>Applying deep learning to images is the main expertise of our team, Cognition. We are Data Scientists and Machine Learning (ML) Engineers that work together to develop image-based ML solutions at scale, helping Adevinta’s marketplaces build better products and experiences for their customers. Adevinta’s mission is to connect buyers and sellers, enabling people to find jobs, homes, cars, consumer goods and more. By making an accessible ML API with features tailored to our different marketplaces’ needs, Adevinta’s marketplaces are empowered with ML tools at a reasonable cost.</p>

<h2 id="text-extraction-in-images-why-its-crucial-for-adevintas-services">Text Extraction in Images: Why It’s Crucial for Adevinta’s Services</h2>
<p>Text extraction from images enables us to:</p>

<ul>
  <li>Detect unwanted content in ads (e.g., insults, hidden messages).</li>
  <li>Better understand image content to improve search capabilities.</li>
  <li>Support more efficient searches using visible text on items.</li>
</ul>

<p>With over 100 million requests per month and growing, our existing Text in Image service was ripe for enhancement. We aimed to improve accuracy and performance, leading to the development of Text in Image 2.0.</p>

<h2 id="why-we-chose-paddleocr-benchmarking-the-best-ocr-solution">Why we chose PaddleOCR: Benchmarking the best OCR solution</h2>

<p>The existing service was based on <a href="https://arxiv.org/abs/1801.01671">Fast Oriented Text Spotting with a Unified Network (Yan et al., 2018)</a>. Despite being state of the art in 2018, the algorithm achieved 0.4 accuracy on our internal benchmark of 200 marketplace images. Nevertheless, accuracy was not the sole criteria of choice for the Text in Image 2.0, so we compiled a list of edge cases where our partner marketplaces require high-performing algorithms.</p>

<p>After reviewing different open source OCR frameworks (including <a href="https://github.com/open-mmlab/mmocr">MMOCR</a>, <a href="https://github.com/JaidedAI/EasyOCR">EASY OCR</a>, <a href="https://github.com/PaddlePaddle/PaddleOCR">PaddleOCR</a> and <a href="https://thehive.ai/apis/ocr">HiveOCR</a>) and different combinations of proposed models on our internal benchmark and on the edge cases, a indisputable winner was PaddleOCR with an average accuracy of 0.8 and an acceptable performance on our edge cases. This result competes with the paid <a href="https://cloud.google.com/vision/docs/ocr">Google Cloud Vision OCR API</a> on the best accuracy we measured.</p>

<p><img src="https://cdn-images-1.medium.com/max/800/0*UUEf-TKs1Lfn7_wx" alt="Graph showing benchmark results for various OCR frameworks" /></p>

<h2 id="how-we-validated-paddleocr-building-a-comprehensive-benchmark">How We Validated PaddleOCR: Building a Comprehensive Benchmark</h2>

<p>In order to construct our independent benchmark and validate the choice of PaddleOCR at scale, we built a “Text in Image generator” that uses open source images from <a href="https://unsplash.com/license">Unsplash</a> and <a href="https://pikwizard.com/free-license">Pikwizard</a> and adds randomly generated text on top of them. The created tool is highly customisable in order to simulate a wide variety of cases that combine factors such as font type, rotation, text length, background type, image resolution etc. Using a simulated benchmark of 20k images with a distribution of cases matching business needs, we obtained an improvement factor of x1.4.</p>

<p><img src="https://cdn-images-1.medium.com/max/800/0*sWpBlrJtdxsRlqj4" alt="Sample of Text in Image generator output showing simulated text scenarios" /></p>

<h2 id="challenges-with-paddleocr-identifying-and-mitigating-issues">Challenges with PaddleOCR: Identifying and mitigating issues</h2>

<p>We identified several cases where PaddleOCR fails. This is mostly when there are different angles of rotated text, some alternative fonts and differing colour/contrast. We also observed that in some cases, the correct words are detected but the spaces between them are not placed correctly. This may or may not be an issue depending on the way the extracted text is used further.</p>

<p><img src="https://cdn-images-1.medium.com/max/800/1*3CO2dWUYPpVPPBZJDpx4EA.png" alt="Example of OCR results with incorrectly spaced text" /></p>

<h2 id="deep-dive-how-we-optimized-paddleocr-for-production">Deep Dive: How We Optimized PaddleOCR for Production</h2>

<p>In order to evaluate the potential for improvement and mitigation of these errors, in addition to defining the serving strategy, we had to deep dive into the PaddleOCR framework.</p>

<p><a href="https://github.com/PaddlePaddle/PaddleOCR">PaddleOCR</a> builds on <a href="https://github.com/PaddlePaddle/Paddle">PaddlePaddle.</a> Our team had no previous experience with this and it’s less popular in our community than other frameworks such as Tensorflow, Keras or Pytorch.</p>

<p>From a technical point of view, PaddleOCR is composed of three distinct models:</p>

<ul>
  <li><strong>Detection</strong>, for detecting a bounding box where possible text is</li>
  <li><strong>Classification</strong>, rotating the text 180° if necessary</li>
  <li><strong>Recognition</strong>, translating the detected image frame to raw text</li>
</ul>

<p>Pre-trained models in different languages are <a href="https://github.com/PaddlePaddle/PaddleOCR/blob/18ddb6d5f9bdc2c1b0aa7f6e399ec0f76119dc87/doc/doc_en/models_list_en.md">provided by authors</a>.</p>

<h3 id="refactoring-paddleocr-creating-a-clean-production-ready-codebase">Refactoring PaddleOCR: Creating a Clean, Production-Ready Codebase</h3>

<p>Whilst exploring the code base of PaddleOCR for inference, we were faced with convoluted code, which was difficult to read and understand. As we wanted to use the PaddleOCR solution in production, we decided to refactor the code, keeping in mind to preserve the performance and the speed of the original code. You can read about the details of that process and the PaddleOCR model in the complementary article of this series. After refactoring the code, we had created a clean and readable code base.</p>

<p>We believe our code version is easier to work with, given the use case of text extraction from images, and are working on making the code available open source. The different steps and pre-processing and post-processing parts are clearly separated, so they can be called independently, which should make further community extensions easier to add. It also makes putting into production easier, as the simplified, modular code combines well with the structure of inference.py for serving SageMaker endpoints. Our proposed code version does not alter predictions (compared to the 2.6 release) for images.</p>

<h2 id="deploying-text-in-image-20-achieving-superior-performance-with-paddleocr">Deploying Text in Image 2.0: Achieving Superior Performance with PaddleOCR</h2>

<p>Using the refactored code, we made the model available as an API. To help our customers’ transition, we maintained the same API contract used in the previous service.</p>

<p>Serving PaddleOCR can be done in multiple ways. The straightforward approach is calling its own Python API (provided by the <a href="https://pypi.org/project/paddleocr/">PaddleOCR</a> package) from within a well-known framework. We selected Multi Model Server, Flask and FastAPI to conduct our benchmark. All our proposed solutions are served by AWS SageMaker Endpoint, building our own container (BYOC) from the same Docker base image.</p>

<p>MultiModel Server uses its own JAVA ModelServer, while for Flask and FastAPI, we use nginx+gunicorn (combined with <a href="https://fastapi.tiangolo.com/deployment/server-workers/">uvicorn workers for the ASGI FastAPI</a>). The frontend for our customers is served by an API Gateway, which is out of the scope of this article.</p>

<h2 id="benchmarking-deployment-options-multi-model-server-flask-and-fastapi">Benchmarking Deployment Options: Multi-Model Server, Flask, and FastAPI</h2>

<p>For the performance testing, we recreated a number of requests with a controlled amount of text and different image sizes, mimicking the expected distribution from our customers. We used <a href="https://locust.io/">Locust</a> as the testing framework, and stimulated heavy bursts in the <a href="https://docs.locust.io/en/stable/writing-a-locustfile.html#wait-time-attribute">waiting time</a> as a stress test.</p>

<p>With the data gathered from the performance tests, we were able to define our infrastructure (type of instance and autoscaling policy) in relation to the Service Level Agreement (SLA) terms, while balancing the risk of a sudden shift from the observed distribution (the service is sensitive to the amount of text per image).</p>

<p>Currently, we deal with 330 million requests per month, and we have estimated that next year, more Adevinta marketplaces will onboard a Text in Image service, resulting in a 400% growth.</p>

<h2 id="results-and-impact-transforming-text-in-image-service-with-paddleocr">Results and impact: Transforming Text in Image service with PaddleOCR</h2>

<p>The new API resulted in an improved latency 7.5x compared to the FOTS-based solution, while providing a 7% cost reduction in serving. Also, since the new API being 12x cheaper than a typical external solution, such as GCP OCR, we received positive feedback from our users about both the speed and the accuracy of the Text in Image 2.0.</p>

<h2 id="key-takeaways-enhancing-ocr-with-paddleocr">Key Takeaways: Enhancing OCR with PaddleOCR</h2>

<p>As a computer vision team working for an international company serving millions of people every day, we aimed to improve our OCR API for text extraction from classified ads. After testing numerous frameworks, we built an image simulator in order to find the algorithm matching the needs of our users. The selected framework, PaddleOCR, went through our internal review and revamp. (There were challenges along the way and you can read more about them in <a href="/works/deep-dive-in-paddleocr-inference"><strong>Article 2: Deep Dive in PaddleOCR inference</strong></a>). Now, we’re pleased to say we’re providing a more accurate, faster and cheaper API using the PaddleOCR framework.</p>

<footer>
  <p>Exported from <a href="https://medium.com">Medium</a> on June 06,
    2023.</p>
  <p><a href="https://medium.com/adevinta-tech-blog/text-in-image-2-0-improving-ocr-service-with-paddleocr-61614c886f93">This article was orignally co-authored by Cognition team members, special credits to Joaquin Cabezas</a></p>
</footer>
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-584ec4ce89deed84"></script>

<div class="addthis_inline_share_toolbox"></div>


      <div class="backnext btnbottom">
                <div class="back">
        </div>
        <div class="next">
        <div class="npointer"><a href="/works/deep-dive-in-paddleocr-inference"
         class="button small" title="Next">Next &gt;</a></div>
         <!-- class="icon fa-forward" title="Next"></a></div> -->
        <div class="ntitle"><a href="/works/deep-dive-in-paddleocr-inference">Deep Dive in PaddleOCR inference</a></div>
        </div>

      </div>
      <script>
      document.body.onkeyup = function(e){
        if (e.keyCode == '37') { window.location = ''; }
        if (e.keyCode == '39') { window.location = '/works/deep-dive-in-paddleocr-inference'; }
      };
      </script>
<hr style="margin-bottom:12px;" />
<div class="author">
<!-- style="margin:8px 28px 12px 0;position:relative;float:left;"> -->
  <!-- style="position: relative; float: left;margin:0;padding:0;" -->
  <div style="display:inline-block;border-radius:7px;overflow:hidden;height:100px;width:100px;background:url(/images/ula.jpg);background-size:100px;"></div>
  <div style="display:inline-block;padding-left:12px;vertical-align:top;"><b>by:<br />Urszula Czerwinska</b><br />(<a href="mailto:urszula.czerwinska@cri-paris.org">urszula.czerwinska@cri-paris.org</a>)<br
    /><i><a href="http://urszulaczerwinska.github.io" target="_blank">http://urszulaczerwinska.github.io</a></i>
  </div>
  <div class="auth-desc"><p> Senior Data Scientist / Deep Learning Engineer </p> PhD in Bio-Mathematics, Data Science & Machine Learning
</div>
</div>
<hr style="margin-top:9px;" />

  
    </div>
  </section>


      </article>

      <!-- Footer -->
<footer id="footer">
  <ul class="icons">
    <li><a target="_blank" href="https://twitter.com/ulalaparis" class="icon fa-twitter"
           ><span class="label">twitter</span></a></li>
    <li><a target="_blank" href="https://github.com/urszulaczerwinska" class="icon fa-github"
           ><span class="label">github</span></a></li>
    <li><a target="_blank" href="https://linkedin.com/in/urszulaczerwinska" class="icon fa-linkedin-square"
           ><span class="label">linkedin-square</span></a></li>
    <li><a target="_blank" href="mailto:ulcia.liberte@gmail.com" class="icon fa-envelope"
           ><span class="label">E-mail</span></a></li>
  </ul>
  <ul class="copyright">
    <li>&copy; 2016,
    2024
      Urszula Czerwinska</li>
    <li><a href="/credits/">Credits</a></li>
  </ul>
</footer>


      <!-- Scripts -->
<script src="/js/jquery.min.js"></script>
<script src="/js/jquery.scrollex.min.js"></script>
<script src="/js/jquery.scrolly.min.js"></script>
<script src="/js/skel.min.js"></script>
<script src="/js/util.js"></script>
<!--[if lte IE 8]><script src="/js/ie/respond.min.js"></script><![endif]-->
<script src="/js/main.js"></script>

    </div>

  </body>



</html>