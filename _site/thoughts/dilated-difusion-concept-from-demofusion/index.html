<!DOCTYPE html>
<!--
  Original Design: Spectral by HTML5 UP
    html5up.net | @n33co
    Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
  Jekyll build mod and further hacks by @arkadianriver, MIT license
-->
<html>
  <head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Dilated Diffusion from DemoFusion</title>
  <meta name="google-site-verification" content="WrNs4kb-PL779UWOhOTLegwiql-42uVzYDfCoJxQRPs" />
  <meta name="description" content="5 Ways It's Transforming AI Image Generation">
  <!--[if lte IE 8]><script src="/js/ie/html5shiv.js"></script><![endif]-->
  <link rel="canonical" href="http://urszulaczerwinska.github.io/thoughts/dilated-difusion-concept-from-demofusion/">
  <link rel="shortcut icon" href="/favicon.ico">

  <link rel="stylesheet" href="/css/main.css" />


  
  <!-- Add JSON-LD for Article and Person Schema -->
  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Article",
      "headline": "Dilated Diffusion from DemoFusion"
      "description": "Discover how DemoFusion's dilated diffusion transforms AI image generation by democratizing high-resolution output through innovative techniques like progres...",
      "datePublished": "2024-06-19T00:00:00+02:00",
      "dateModified": "2024-06-19T00:00:00+02:00",
      "keywords": "",
      "author": {
        "@type": "Person",
        "name": "Urszula Czerwinska",
        "description": "Data Scientist & Deep Learning Engineer",
        "url": "https://www.linkedin.com/in/urszula-czerwinska/"
      },
      "image": {
        "@type": "ImageObject",
        "url": "http://urszulaczerwinska.github.io/images/writing.jpeg",
        "width": 1200,
        "height": 630
      },
      "publisher": {
        "@type": "Organization",
        "name": "Urszula Czerwinska",
        "logo": {
          "@type": "ImageObject",
          "url": "http://urszulaczerwinska.github.io/images/logo.png",
          "width": 60,
          "height": 60
        }
      },
      "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://urszulaczerwinska.github.io/thoughts/dilated-difusion-concept-from-demofusion/"
      }
    }
</script>


  <!--[if lte IE 8]><link rel="stylesheet" href="/css/ie8.css" /><![endif]-->
  <!--[if lte IE 9]><link rel="stylesheet" href="/css/ie9.css" /><![endif]-->
  <style>
  #main > header {
    background-image: -moz-linear-gradient(top, rgba(0,0,0,0.5), rgba(0,0,0,0.5)), url("/images/dilated.jpg");
    background-image: -webkit-linear-gradient(top, rgba(0,0,0,0.5), rgba(0,0,0,0.5)), url("/images/dilated.jpg");
    background-image: -ms-linear-gradient(top, rgba(0,0,0,0.5), rgba(0,0,0,0.5)), url("/images/dilated.jpg");
    background-image: linear-gradient(top, rgba(0,0,0,0.5), rgba(0,0,0,0.5)), url("/images/dilated.jpg");
  }
  </style>
  <!--[if lte IE 9]>
  <style>
  #main > header {
    background-image: url("/images/dilated.jpg");
  }
  </style>
  -->
  <link rel="alternate" type="application/rss+xml" title="Urszula Czerwinska | Python, TensorFlow Expert | Data Scientist & Deep Learning Engineer" href="http://urszulaczerwinska.github.io/feed.xml">
</head>

  <!-- Semantic Schema generated by InLinks -->


  
  <body>


    <!-- Page Wrapper -->
    <div id="page-wrapper">

      <!-- Header -->
<header id="header">
  <h1><a href="/index.html"> <span><img src="/favicon.ico" alt="Logo" style="height: 40px; vertical-align: middle; margin-right: 5px;"> Urszula Czerwinska </span></a></h1>
  <nav id="nav">
    <ul>
      <li class="special">
        <a href="#menu" class="menuToggle">  <span>
          Menu
        </span></a>
        <div id="menu">
          <ul>
            <li><a href="/index.html">Home</a></li>
            <li><a href="/about/">About</a></li>
            <li><a href="/works/">Works</a></li>
            <li><a href="/thoughts/">Thoughts</a></li>
            <li><a href="/feed.xml"
                   class="icon fa-feed"> RSS Feed</a></li>
          </ul>
        </div>
      </li>
    </ul>
  </nav>
</header>


      <article id="main">

          <header>
    <h2>Dilated Diffusion from DemoFusion</h2>
    <p>5 Ways It's Transforming AI Image Generation</p>
  </header>
  <ul class="breadcrumb">
  <li><a href="/index.html">Home</a></li>
  <li>Dilated Diffusion from DemoFusion</li>
</ul>



          <section class="wrapper style5">
    <div class="inner">
      <span id="post-date">19 June 2024</span><hr
        style="margin-top:3px;" />

      <head>
  <meta name="description" content="Learn how DemoFusion’s dilated diffusion revolutionizes AI image generation, making high-resolution results accessible using standard hardware. Dive into dilated sampling and progressive upscaling techniques." />
</head>

<p><strong>TDLR:</strong> see demo of dilated diffusion <a href="https://colab.research.google.com/drive/1gHCjibaI91a50bXjYbemUE7khRdZmyle?usp=sharing">in a collab</a></p>

<p><span class="image fit">
<img src="https://cdn-images-1.medium.com/max/800/0*ZPCdjBebme6X_8-0.png" alt="Graphical representation of dilated sampling in stable diffusion Unicorn diffusion art" />
</span></p>

<p>At the #CVPR24 best paper review, I came across an exciting stable diffusion paper.</p>

<h2 id="demofusion-unlocking-high-resolution-ai-image-generation-with-dilated-diffusion">DemoFusion: Unlocking High-Resolution AI Image Generation with Dilated Diffusion</h2>

<p><a href="https://ruoyidu.github.io/demofusion/demofusion.html" title="https://ruoyidu.github.io/demofusion/demofusion.html"><strong>DemoFusion</strong> <em>Democratising High-resolution Image Generation without a Sweat</em></a></p>

<p>The goal of this research is to democratize high-resolution image generation while reducing costs. DemoFusion extends Latent Diffusion Models (LDMs) by introducing Progressive Upscaling, Skip Residuals, and Dilated Sampling mechanisms.</p>

<h3 id="key-features-of-demofusion">Key Features of DemoFusion:</h3>
<ol>
  <li><strong>Progressive Upscaling</strong>: Iteratively increases image resolution using lower-resolution results as a base.</li>
  <li><strong>Upsample-Diffuse-Denoise Loop</strong>: Utilizes noise-inverted representations for guiding higher resolution generation.</li>
  <li><strong>Dilated Sampling</strong>: Enhances global context, resulting in more coherent image generation.</li>
</ol>

<h3 id="applications-of-demofusion">Applications of DemoFusion:</h3>

<ul>
  <li>Generate high-resolution images up to <strong>4096×4096</strong> using standard hardware like an RTX 3090 GPU.</li>
  <li>Integrate with <strong>ControlNet</strong> for additional functionality.</li>
  <li>Upscale existing images by encoding them into the LDM’s latent space.</li>
</ul>

<p><strong>Bonus:</strong> Intermediate results are available during the generation process, enabling rapid iteration and previewing.</p>

<p>Check out more demos <a href="https://replicate.com/lucataco/demofusion">here</a>.</p>

<hr />

<h2 id="exploring-the-concept-and-benefits-of-dilated-sampling-in-ai-image-generation">Exploring the Concept and Benefits of Dilated Sampling in AI Image Generation</h2>

<p><span class="image fit">
<img src="https://cdn-images-1.medium.com/max/800/1*-1ylqkgPXbdNxeTMw9MstA.png" alt="Visual concept of dilated diffusion process, showing pixel grids and sampling gaps" />
</span></p>

<h3 id="concept-of-dilated-sampling">Concept of Dilated Sampling:</h3>

<p>Imagine an image as a grid of pixels. Instead of processing each pixel in sequence, <strong>dilated sampling</strong> selects every second or third pixel, which creates a broader view of the image. This technique enables fewer steps, while providing a broader context for denoising and refining images.</p>

<h3 id="purpose-of-dilated-sampling">Purpose of Dilated Sampling:</h3>

<p>The goal is to capture global image information instead of focusing on small local details. This method helps establish a global context, leading to more cohesive and coherent image generation.</p>

<h3 id="implementation-of-dilated-sampling">Implementation of Dilated Sampling:</h3>

<ul>
  <li>A regular pattern is avoided; instead, dilated sampling skips pixels based on a <em>dilation factor</em>. For example, if the dilation factor is 2, every second pixel is picked.</li>
  <li><strong>Shifting and Combining</strong>: The sampling shifts its starting point in each round to ensure complete image coverage.</li>
</ul>

<h3 id="preventing-image-graininess">Preventing Image Graininess:</h3>

<p>One drawback of dilated sampling is the potential for graininess, as the sampled pixels are spread apart. To counter this, a <strong>Gaussian filter</strong> smooths the image before sampling, ensuring the sampled points represent the image more accurately.</p>

<h3 id="conclusion-how-dilated-sampling-enhances-ai-image-generation">Conclusion: How Dilated Sampling Enhances AI Image Generation</h3>

<p>Think of dilated sampling like stepping back to admire an entire painting before focusing on the details. This technique strikes a balance between global perspective and fine detail, resulting in high-quality images.</p>

<hr />

<h2 id="step-by-step-code-implementation">Step-by-Step Code Implementation</h2>

<p>For those interested in the technical details, full code is available on GitHub: <a href="https://github.com/PRIS-CV/DemoFusion/blob/main/pipeline_demofusion_sdxl.py">DemoFusion GitHub Repository</a>.</p>

<h3 id="code-step-bystep">CODE STEP BY STEP</h3>

<p>Full code can be found in author’s github: <a href="https://github.com/PRIS-CV/DemoFusion/blob/main/pipeline_demofusion_sdxl.py">https://github.com/PRIS-CV/DemoFusion/blob/main/pipeline_demofusion_sdxl.py</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">views</span> <span class="o">=</span> <span class="p">[[</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">]</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">current_scale_num</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">current_scale_num</span><span class="p">)]</span>
<span class="n">views_batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">views</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">view_batch_size</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">views</span><span class="p">),</span> <span class="n">view_batch_size</span><span class="p">)]</span>
</code></pre></div></div>
<p>Here, `views` and `views_batch` set up the grid for dilated sampling. `current_scale_num` determines the dilation factor, creating a sparse sampling grid.</p>

<p>Gather more global information about the image rather than focusing on local details.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Grid for dilated sampling
</span><span class="n">count_global</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">latents_</span><span class="p">)</span>
<span class="n">value_global</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">latents_</span><span class="p">)</span>
</code></pre></div></div>
<p>`count_global` and `value_global` are initialized to aggregate global information.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Loop for picking pixels with gaps
</span><span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">batch_view</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">views_batch</span><span class="p">):</span>
  <span class="n">latents_for_view</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">(</span> <span class="p">[</span> <span class="n">latents_</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">h</span><span class="p">::</span><span class="n">current_scale_num</span><span class="p">,</span> <span class="n">w</span><span class="p">::</span><span class="n">current_scale_num</span><span class="p">]</span> <span class="k">for</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">batch_view</span> <span class="p">])</span>
</code></pre></div></div>
<p>The loop iterates through `views_batch`, picking pixels with a gap determined by `current_scale_num`.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">batch_view</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">views_batch</span><span class="p">):</span>
  <span class="n">latents_for_view_gaussian</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">latents_gaussian</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">h</span><span class="p">::</span><span class="n">current_scale_num</span><span class="p">,</span> <span class="n">w</span><span class="p">::</span><span class="n">current_scale_num</span><span class="p">]</span> <span class="k">for</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">batch_view</span><span class="p">])</span>
</code></pre></div></div>
<p>`latents_for_view_gaussian` ensures the global context is gathered, then combined with local details later.</p>

<p>Shifted dilated sampling means the starting point shifts to cover different parts of the image. The global context is combined with local details to refine the final image.</p>

<p>Gaussian filter is applied to smooth the image before sampling</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">std_</span><span class="p">,</span> <span class="n">mean_</span> <span class="o">=</span> <span class="n">latents_</span><span class="p">.</span><span class="nf">std</span><span class="p">(),</span> <span class="n">latents_</span><span class="p">.</span><span class="nf">mean</span><span class="p">()</span>
<span class="n">latents_gaussian</span> <span class="o">=</span> <span class="nf">gaussian_filter</span><span class="p">(</span><span class="n">latents_</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">current_scale_num</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="o">*</span><span class="n">c3</span><span class="p">)</span>
<span class="n">latents_gaussian</span> <span class="o">=</span> <span class="p">(</span><span class="n">latents_gaussian</span> <span class="err">—</span> <span class="n">latents_gaussian</span><span class="p">.</span><span class="nf">mean</span><span class="p">())</span> <span class="o">/</span> <span class="n">latents_gaussian</span><span class="p">.</span><span class="nf">std</span><span class="p">()</span> <span class="o">*</span> <span class="n">std_</span> <span class="o">+</span> <span class="n">mean_</span>
</code></pre></div></div>
<h3 id="smart-blending"><strong>Smart Blending</strong></h3>

<p>Combining global and local details ensures that the image retains the broader context and finer details.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">latents_view_denoised</span><span class="p">,</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span> <span class="n">latents_denoised_batch</span><span class="p">.</span><span class="nf">chunk</span><span class="p">(</span><span class="n">vb_size</span><span class="p">),</span> <span class="n">batch_view</span><span class="p">):</span>
 <span class="n">value_global</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">h</span><span class="p">::</span><span class="n">current_scale_num</span><span class="p">,</span> <span class="n">w</span><span class="p">::</span><span class="n">current_scale_num</span><span class="p">]</span> <span class="o">+=</span> <span class="n">latents_view_denoised</span>
 <span class="n">count_global</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">h</span><span class="p">::</span><span class="n">current_scale_num</span><span class="p">,</span> <span class="n">w</span><span class="p">::</span><span class="n">current_scale_num</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div></div>
<p>Here, denoised views (`latents_view_denoised`) are added to `value_global`, blending the global and local contexts.</p>

<p>The final latent representation is formed by blending global and local contexts.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">value_global</span> <span class="o">=</span> <span class="n">value_global</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">h_pad</span><span class="p">:,</span> <span class="n">w_pad</span><span class="p">:]</span>
<span class="n">value</span> <span class="o">+=</span> <span class="n">value_global</span> <span class="o">*</span> <span class="n">c2</span>
<span class="n">count</span> <span class="o">+=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones_like</span><span class="p">(</span><span class="n">value_global</span><span class="p">)</span> <span class="o">*</span> <span class="n">c2</span>
<span class="n">latents</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">value</span> <span class="o">/</span> <span class="n">count</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
</code></pre></div></div>

<p>The global values are combined with local values (`value += value_global * c2`) and normalized (`latents = torch.where(count &gt; 0, value / count, value)`).</p>

<h3 id="conclusion">CONCLUSION </h3>

<p>This code implements dilated sampling by creating a grid with gaps (dilation), applying a Gaussian filter to smooth out graininess, gathering global context, and then blending it with local details to form the final denoised image. This process ensures a balance between capturing the big picture and refining the details.</p>

<p>Try out a simple demo illustrating the concept of dilated sampling</p>

<p><a href="https://colab.research.google.com/drive/1gHCjibaI91a50bXjYbemUE7khRdZmyle?usp=sharing">Collab demo</a></p>

<p>The demo is a simple illustration of the dilated sampling concept using simulated data. The visualizations help in understanding how dilated sampling and smoothing work together.</p>

<ol>
  <li>Original Image:
 — A simple checkboard patten image is created for demonstration.</li>
  <li>Smoothed Image (Gaussian Filter):
 — The original image is smoothed using a Gaussian filter to reduce graininess.</li>
  <li>Dilated Sampling after Smoothing:
 — Dilated sampling is applied to the smoothed image, resulting in a more coherent global context.</li>
  <li>Dilated Sampling:
 — Pixels are sampled with a gap (dilation factor).</li>
</ol>

<footer>
  <p>Exported from <a href="https://medium.com">Medium</a> in June 2024.</p>
  <p><a href="https://medium.com/@ulalaparis/dilated-difusion-concept-from-demofusion-e32a7b5d09d6">View
      the original</a></p>
</footer>
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-584ec4ce89deed84"></script>

<div class="addthis_inline_share_toolbox"></div>


<hr style="margin-bottom:12px;" />
<div class="author">
<!-- style="margin:8px 28px 12px 0;position:relative;float:left;"> -->
  <!-- style="position: relative; float: left;margin:0;padding:0;" -->
  <div style="display:inline-block;border-radius:7px;overflow:hidden;height:100px;width:100px;background:url(/images/ula.jpg);background-size:100px;"></div>
  <div style="display:inline-block;padding-left:12px;vertical-align:top;"><b>by:<br />Urszula Czerwinska</b><br />(<a href="mailto:urszula.czerwinska@cri-paris.org">urszula.czerwinska@cri-paris.org</a>)<br
    /><i><a href="http://urszulaczerwinska.github.io" target="_blank">http://urszulaczerwinska.github.io</a></i>
  </div>
  <div class="auth-desc"><p> Senior Data Scientist / Deep Learning Engineer </p> PhD in Bio-Mathematics, Data Science & Machine Learning
</div>
</div>
<hr style="margin-top:9px;" />

  
    </div>
  </section>


      </article>

      <!-- Footer -->
<footer id="footer">
  <ul class="icons">
    <li><a target="_blank" href="https://twitter.com/ulalaparis" class="icon fa-twitter"
           ><span class="label">twitter</span></a></li>
    <li><a target="_blank" href="https://github.com/urszulaczerwinska" class="icon fa-github"
           ><span class="label">github</span></a></li>
    <li><a target="_blank" href="https://linkedin.com/in/urszulaczerwinska" class="icon fa-linkedin-square"
           ><span class="label">linkedin-square</span></a></li>
    <li><a target="_blank" href="mailto:ulcia.liberte@gmail.com" class="icon fa-envelope"
           ><span class="label">E-mail</span></a></li>
  </ul>
  <ul class="copyright">
    <li>&copy; 2016,
    2024
      Urszula Czerwinska</li>
    <li><a href="/credits/">Credits</a></li>
  </ul>
</footer>


      <!-- Scripts -->
<script src="/js/jquery.min.js"></script>
<script src="/js/jquery.scrollex.min.js"></script>
<script src="/js/jquery.scrolly.min.js"></script>
<script src="/js/skel.min.js"></script>
<script src="/js/util.js"></script>
<!--[if lte IE 8]><script src="/js/ie/respond.min.js"></script><![endif]-->
<script src="/js/main.js"></script>

    </div>

  </body>



</html>